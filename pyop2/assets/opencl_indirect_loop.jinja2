{% import 'opencl_common.jinja2' as common %}

{%- macro header() -%}
/* Launch configuration:
 *   work group size     : {{ launch.work_group_size }}
 *   partition size      : {{ launch.partition_size }}
 *   local memory size   : {{ launch.local_memory_size }}
 *   local memory offset : {{ launch.local_memory_offset }}
 *   warpsize            : {{ launch.warpsize }}
 */
{{ common.pragma_clext(parloop) }}

{{ common.defines(launch) }}
{%- endmacro -%}

{%- macro stagingin(arg) -%}
  for (i_1 = get_local_id(0); i_1 < {{ arg._size_name }} * {{ arg.data.cdim }}; i_1 += get_local_size(0)) {
  {{ arg._shared_name }}[i_1] = {{ arg._name }}[i_1 % {{ arg.data.cdim }} + {{ arg._map_name }}[i_1 / {{ arg.data.cdim }}] * {{ arg.data.cdim }}];
}
{%- endmacro -%}

{%- macro stagingout(arg) -%}
  for (i_1 = get_local_id(0); i_1 < {{ arg._size_name }} * {{ arg.data.cdim }}; i_1 += get_local_size(0)) {
  {{ arg.data.name }}[i_1 % {{ arg.data.cdim }} + {{ arg._map_name }}[i_1 / {{ arg.data.cdim }}] * {{ arg.data.cdim }}] = {{ arg._shared_name }}[i_1];
}
{%- endmacro -%}

{%- macro populate_vec_map(arg) -%}
// populate vec map
{%- if(arg._is_indirect_reduction) -%}
{%- for i in range(arg.map.dim) %}
{{ arg._vec_name }}[{{ i }}] = {{ arg._local_name(idx=i) }};
{% endfor -%}
{%- else -%}
{%- for i in range(arg.map.dim) %}
{{ arg._vec_name }}[{{ i }}] = &{{ arg._shared_name }}[p_loc_map[i_1 + {{arg._which_indirect + i}}*set_size + shared_memory_offset] * {{ arg.data.cdim }}];
{%- endfor -%}
{%- endif -%}
{%- endmacro -%}

{%- macro staged_arg_local_variable_zeroing(arg) -%}
for (i_2 = 0; i_2 < {{ arg.data.cdim }}; ++i_2) {
    {%- if (arg._is_vec_map or arg._uses_itspace) -%}
    {% for i in range(arg.map.dim) %}
    {{ arg._local_name(idx=i) }}[i_2] = {{arg.data._cl_type_zero}};
    {% endfor %}
    {% else %}
    {{ arg._local_name() }}[i_2] = {{ arg.data._cl_type_zero }};
    {% endif %}
}
{%- endmacro -%}

{%- macro color_reduction(arg) -%}
for (i_2 = 0; i_2 < {{ arg.data.cdim }}; ++i_2) {
   {%- if(arg._is_INC) %}
   {{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect}}*set_size] * {{ arg.data.cdim }}] += {{ arg._local_name() }}[i_2];
   {% elif(arg._is_MIN) %}
   {{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {(arg._which_indirect}}*set_size] * {{ arg.data.cdim }}] = min({{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect}}*set_size] * {{ arg.data.cdim }}], {{ arg._local_name() }}[i_2]);
   {% elif(arg._is_MAX) %}
   {{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect}}*set_size] * {{ arg.data.cdim }}] = max({{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect}}*set_size] * {{ arg.data.cdim }}], {{ arg._local_name() }}[i_2]);
   {% endif %}
}
{%- endmacro -%}

{%- macro color_reduction_vec_map(arg) -%}
for (i_2 = 0; i_2 < {{ arg.data.cdim }}; ++i_2) {
    {% for i in range(arg.map.dim) %}
   {%- if(arg._is_INC) %}
   {{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect + i}}*set_size] * {{ arg.data.cdim }}] += {{ arg._local_name(idx=i) }}[i_2];
   {% elif(arg._is_MIN) %}
   {{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {(arg._which_indirect + i}}*set_size] * {{ arg.data.cdim }}] = min({{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect + i}}*set_size] * {{ arg.data.cdim }}], {{ arg._local_name(idx=i) }}[i_2]);
   {% elif(arg._is_MAX) %}
   {{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect + i}}*set_size] * {{ arg.data.cdim }}] = max({{ arg._shared_name }}[i_2 + p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect + i}}*set_size] * {{ arg.data.cdim }}], {{ arg._local_name(idx=i) }}[i_2]);
   {% endif %}
   {% endfor %}
}
{%- endmacro -%}

{%- macro work_group_reduction(arg) -%}
  for (i_1 = get_local_id(0); i_1 < {{ arg._size_name }} * {{ arg.data.cdim }}; i_1 += get_local_size(0)) {
  {{ arg.data.name }}[i_1 % {{ arg.data.cdim }} + {{ arg._map_name }}[i_1 / {{ arg.data.cdim }}] * {{ arg.data.cdim }}] += {{ arg._shared_name }}[i_1];
}
{%- endmacro -%}

{%- macro global_reduction_local_zeroing(arg) -%}
for (i_1 = 0; i_1 < {{ arg.data.cdim }}; ++i_1) {
  {{ arg._reduction_local_name }}[i_1] = {{ common.reduction_id_value(arg) }};
}
{%- endmacro -%}

{%- macro on_device_global_reduction(arg) -%}
for (i_1 = 0; i_1 < {{ arg.data.cdim }}; ++i_1)
{
    {{ arg._reduction_kernel_name }}(&{{ arg._name }}[i_1 + get_group_id(0) * {{ arg.data.cdim }}], {{ arg._reduction_local_name }}[i_1], (__local {{ arg.data._cl_type }}*) shared);
}
{%- endmacro -%}

{%- macro kernel_stub() -%}
__kernel
__attribute__((reqd_work_group_size({{ launch.work_group_size }}, 1, 1)))
void {{ parloop._stub_name }}(
  {%- for arg in parloop._unique_dat_args %}
  __global {{ arg.data._cl_type }}* {{ arg._name }},
  {%- endfor -%}
  {% for arg in parloop._all_global_non_reduction_args %}
  __global {{ arg.data._cl_type }}* {{ arg.data.name }},
  {%- endfor -%}
  {% for arg in parloop._all_global_reduction_args %}
  __global {{ arg.data._cl_type }}* {{ arg._name }},
  {%- endfor -%}
  {% for c in op2const %}
  __constant {{ c._cl_type }}* {{ c.name }},
  {% endfor %}
  {% for mat in parloop._unique_matrix %}
  __global {{ mat._cl_type }}* {{ mat.name }},
  __global int* {{ mat.name }}_rowptr,
  __global int* {{ mat.name }}_colidx,
  {%- endfor -%}
  {% for matem in parloop._matrix_entry_maps %}
  __global int* {{ matem.name }},
  {%- endfor -%}
  int set_size,
  __global int* p_ind_map,
  __global short *p_loc_map,
  __global int* p_ind_sizes,
  __global int* p_ind_offsets,
  __global int* p_blk_map,
  __global int* p_offset,
  __global int* p_nelems,
  __global int* p_nthrcol,
  __global int* p_thrcol,
  __private int block_offset
) {
  __local char shared [{{ launch.local_memory_size }}] __attribute__((aligned(sizeof(long))));
  __local int shared_memory_offset;
  __local int active_threads_count;

  int nbytes;
  int block_id;

  int i_1;

{%- if(parloop._requires_coloring) %}
  __local int colors_count;
  __local int active_threads_count_ceiling;
  int color_1;
  int color_2;
  int i_2;
{% endif %}

{%- if(parloop._unique_indirect_dat_args) %}
  // reduction args
{%- for arg in parloop._all_inc_non_vec_map_indirect_dat_args %}
  {{ arg.data._cl_type }} {{ arg._local_name() }}[{{ arg.data.cdim }}];
{%- endfor %}

{%- for arg in parloop._all_inc_vec_map_args %}
{% for i in range(arg.map.dim) %}
{{arg.data._cl_type}} {{arg._local_name(idx=i)}}[{{arg.data.cdim}}];
{%- endfor %}
{%- endfor %}

{%- for arg in parloop._all_inc_itspace_dat_args %}
{% for i in range(arg.map.dim) %}
{{arg.data._cl_type}} {{arg._local_name(idx=i)}}[{{arg.data.cdim}}];
{%- endfor %}
{%- endfor %}
{%- endif %}

{%- if(parloop._all_global_reduction_args) %}
  // global reduction local declarations
{% for arg in parloop._all_global_reduction_args %}
  {{ arg.data._cl_type }} {{ arg._reduction_local_name }}[{{ arg.data.cdim }}];
{%- endfor %}
{%- endif %}

{% if(parloop._matrix_args) %}
  // local matrix entry
  {% for arg in parloop._matrix_args %}
  __private {{ arg.data._cl_type }} {{ arg.data.name }}_entry
  {%- for it in parloop._it_space._extent_ranges -%}[{{ it }}]{%- endfor -%}
  {%- for dim in arg.data.sparsity.dims %}[{{ dim }}]{% endfor %};
  {% endfor %}
{% endif %}

  // shared indirection mappings
{%- for arg in parloop._unique_indirect_dat_args %}
  __global int* __local {{ arg._map_name }};
  __local int {{ arg._size_name }};
  __local {{ arg.data._cl_type }}* __local {{ arg._shared_name }};
{%- endfor %}
{% for arg  in parloop._all_non_inc_vec_map_args %}
  __local {{ arg.data._cl_type }}* {{ arg._vec_name }}[{{ arg.map.dim }}];
{%- endfor %}
{% for arg in parloop._all_inc_vec_map_args %}
  {{ arg.data._cl_type }}* {{ arg._vec_name }}[{{ arg.map.dim }}];
{%- endfor %}
{% for arg in parloop._all_non_inc_itspace_dat_args %}
  __local {{ arg.data._cl_type }}* {{ arg._vec_name }}[{{ arg.map.dim }}];
{%- endfor %}
{% for arg in parloop._all_inc_itspace_dat_args %}
  {{ arg.data._cl_type }}* {{ arg._vec_name }}[{{ arg.map.dim }}];
{%- endfor %}

  if (get_local_id(0) == 0) {
    block_id = p_blk_map[get_group_id(0) + block_offset];
    active_threads_count = p_nelems[block_id];
{%- if(parloop._requires_coloring) %}
    active_threads_count_ceiling = get_local_size(0) * (1 + (active_threads_count - 1) / get_local_size(0));
    colors_count = p_nthrcol[block_id];
{%- endif %}
    shared_memory_offset = p_offset[block_id];
    {% for arg in parloop._unique_indirect_dat_args -%}
    {{ arg._size_name }} = p_ind_sizes[{{loop.index0}} + block_id * {{ loop.length }}];
    {{ arg._map_name }} = &p_ind_map[{{arg._which_indirect}} * set_size] + p_ind_offsets[{{loop.index0}} + block_id * {{loop.length}}];
{%- endfor %}

    nbytes = 0;
{%- for arg in parloop._unique_indirect_dat_args %}
    {{ arg._shared_name }} = (__local {{ arg.data._cl_type }}*) (&shared[nbytes]);
    nbytes += ROUND_UP({{arg._size_name }} * {{ arg.data.cdim }} * sizeof({{ arg.data._cl_type }}));
{%- endfor %}
  }
  barrier(CLK_LOCAL_MEM_FENCE);

{% if(parloop._unique_read_or_rw_indirect_dat_args) -%}
  // staging in of indirect dats
  {% for arg in parloop._unique_read_or_rw_indirect_dat_args %}
  {{ stagingin(arg) }}
  {% endfor %}
  barrier(CLK_LOCAL_MEM_FENCE);
{% endif %}

{%- if(parloop._unique_inc_indirect_dat_args) %}
  // zeroing local memory for indirect reduction
  {% for arg in parloop._unique_inc_indirect_dat_args %}
  {{ shared_memory_reduc_zeroing(arg) | indent(2) }}
  {% endfor %}
  barrier(CLK_LOCAL_MEM_FENCE);
{% endif %}

{%- if(parloop._all_global_reduction_args) %}
  // zeroing private memory for global reduction
  {% for arg in parloop._all_global_reduction_args %}
  {{ global_reduction_local_zeroing(arg) }}
  {% endfor %}
{% endif %}

{%- if(parloop._requires_coloring) %}
  for (i_1 = get_local_id(0); i_1 < active_threads_count_ceiling; i_1 += get_local_size(0)) {
    color_2 = -1;
    if (i_1 < active_threads_count) {
      {% for arg in parloop._all_inc_indirect_dat_args %}
      {{ staged_arg_local_variable_zeroing(arg) | indent(6) }}
      {%- endfor %}

      {{ kernel_call() | indent(6) }}
      color_2 = p_thrcol[i_1 + shared_memory_offset];
    }
    for (color_1 = 0; color_1 < colors_count; ++color_1) {
      // should there be a if + barrier pattern for each indirect reduction argument ?
      if (color_2 == color_1) {
        {% for arg in parloop._all_inc_non_vec_map_indirect_dat_args %}
        {{ color_reduction(arg) | indent(8) }}
        {% endfor %}
        {% for arg in parloop._all_inc_vec_map_args %}
        {{ color_reduction_vec_map(arg) | indent(8) }}
        {% endfor %}
        {% for arg in parloop._all_inc_itspace_dat_args %}
        {{ color_reduction_vec_map(arg) | indent(8) }}
        {% endfor %}
        {%- if(parloop._requires_matrix_coloring) %}
        // IterationSpace index loops ({{ parloop._it_space._extent_ranges }})
        {%- for it in parloop._it_space._extent_ranges %}
        for (int idx_{{ loop.index0 }} = 0; idx_{{ loop.index0 }} < {{ it }}; ++idx_{{ loop.index0 }})
        {%- endfor %}
            {{ matrix_insert() }}
        {% endif %}
      }
      barrier(CLK_LOCAL_MEM_FENCE);
    }
  }
{%- else %}
  for (i_1 = get_local_id(0); i_1 < active_threads_count; i_1 += get_local_size(0)) {
    {{ kernel_call() | indent(6) }}
  }
{%- endif %}

{%- if(parloop._unique_inc_indirect_dat_args) %}
  {% for arg in parloop._unique_inc_indirect_dat_args %}
  {{ work_group_reduction(arg) | indent(2) }}
  {%- endfor %}
{%- endif %}

{%- if(parloop._unique_write_or_rw_indirect_dat_args) %}
  // staging out indirect dats
  barrier(CLK_LOCAL_MEM_FENCE);
  {% for arg in parloop._unique_write_or_rw_indirect_dat_args %}
  {{ stagingout(arg) | indent(2) }}
  {%- endfor %}
{%- endif %}

{%- if(parloop._all_global_reduction_args) %}
  barrier(CLK_LOCAL_MEM_FENCE);
  // on device global reductions
  {% for arg in parloop._all_global_reduction_args %}
  {{ on_device_global_reduction(arg) | indent(2) }}
  {%- endfor %}
{%- endif %}
}
{%- endmacro -%}

{#- rewrite: do recursive template -#}
{%- macro matrix_kernel_call() -%}
// IterationSpace index loops ({{ parloop._it_space._extent_ranges }})
{%- for it in parloop._it_space._extent_ranges %}
for (int idx_{{ loop.index0 }} = 0; idx_{{ loop.index0 }} < {{ it }}; ++idx_{{ loop.index0 }}) {
{%- endfor %}
{% for arg in parloop._matrix_args %}
{% for dim in arg.data.sparsity.dims %}
for (int i{{ loop.index0 }}=0; i{{ loop.index0 }}<{{ dim }}; ++i{{ loop.index0 }})
{%- endfor %}
  {{ arg.data.name }}_entry[idx_0][idx_1][i0][i1] = {{ arg.data._cl_type_zero }};
{% endfor %}
{{ parloop._kernel.name }}(
  {% filter trim|replace("\n", ",\n") -%}
  {%- for arg in parloop.args %}
  {{ kernel_call_arg(arg) }}
  {%- endfor -%}
  {{- kernel_call_const_args() -}}
  {%- for ext in parloop._it_space._extent_ranges %}
  idx_{{ loop.index0 }}
  {%- endfor -%}
  {%- endfilter %}
  );

{%- if(not parloop._requires_matrix_coloring) -%}
{{ matrix_insert() }}
{% endif %}

{%- for it in parloop._it_space._extent_ranges %}
}
{%- endfor -%}
{%- endmacro -%}

{%- macro matrix_insert() -%}
{% for arg in parloop._matrix_args -%}
{% for dim in arg.data.sparsity.dims %}
for (int i{{ loop.index0 }}=0; i{{ loop.index0 }}<{{ dim }}; ++i{{ loop.index0 }})
{%- endfor %}
  {% if(arg._is_INC) -%}
    matrix_add
  {%- else -%}
    matrix_set
  {%- endif -%}(
    {{ arg.data.name }},
    {{ arg.data.name }}_rowptr,
    {{ arg.data.name }}_colidx,
    {%- for map in arg._map %}
    {% set ext = parloop._it_space._extent_ranges[loop.index0] -%}
    {% set dim = arg.data.sparsity.dims[loop.index0] -%}
    {{ dim }}*{{ map.name }}[(i_1 + shared_memory_offset) * {{ ext }} + idx_{{ loop.index0 }}]+i{{ loop.index0 }},
    {%- endfor %}
    {{ arg.data.name }}_entry[idx_0][idx_1][i0][i1]
  );
{% endfor %}
{%- endmacro -%}

{%- macro kernel_call() -%}
{% for arg in parloop._unique_dat_args if(arg._is_vec_map or arg._uses_itspace) %}
  {{ populate_vec_map(arg) }}
{% endfor %}
{% if(parloop._has_itspace) %}
{{ matrix_kernel_call() }}
{% else %}
{{ parloop._kernel.name }}(
  {% filter trim|replace("\n", ",\n") -%}
  {%- for arg in parloop.args -%}
  {{ kernel_call_arg(arg) }}
  {% endfor -%}
  {{ kernel_call_const_args() }}
  {%- endfilter %}
);
{% endif %}
{%- endmacro -%}

{%- macro kernel_call_const_args() -%}
{%- for c in op2const -%}
{% if(c._is_scalar) %}*{% endif %}{{ c.name }}
{% endfor -%}
{%- endmacro -%}

{%- macro kernel_call_arg(arg) -%}
{% if(arg._is_direct) -%}
  {{ typecast("__global", arg.data._cl_type + "*", "__private") -}}
  ({{ arg.data.name }} + (i_1 + shared_memory_offset) * {{ arg.data.cdim }})
{%- elif(arg._is_mat) -%}
  {{ arg.data.name }}_entry[idx_0][idx_1]
{%- elif(arg._uses_itspace) -%}
  {{ arg._vec_name }}[idx_0]
{%- elif(arg._is_vec_map) -%}
  {{ arg._vec_name }}
{%- elif(arg._is_global_reduction) -%}
  {{ arg._reduction_local_name }}
{%- elif(arg._is_indirect_reduction) -%}
  {{ arg._local_name() }}
{%- elif(arg._is_global) -%}
  {{ arg.data.name }}
{%- else -%}
&{{ arg._shared_name }}[p_loc_map[i_1 + shared_memory_offset + {{arg._which_indirect}}*set_size] * {{ arg.data.cdim }}]
{%- endif -%}
{%- endmacro -%}

{%- macro typecast(storage, type, qualifier) -%}
({{ storage }} {{ type }}{% if(not codegen.amd) %} {{ qualifier }}{% endif %})
{%- endmacro -%}

{%- macro shared_memory_reduc_zeroing(arg) -%}
for (i_1 = get_local_id(0); i_1 < {{ arg._size_name }} * {{ arg.data.cdim }}; i_1 += get_local_size(0)) {
  {{ arg._shared_name }}[i_1] = 0;
}
{%- endmacro -%}

{{- header() }}

{% for arg in parloop._all_global_reduction_args -%}
  {{ common.reduction_kernel(arg) }}
{% endfor %}
{% if(parloop._matrix_args) %}
{{ common.matrix_support() }}
{% endif %}
{{ user_kernel }}
{{ kernel_stub() }}
