group opencl_direct_loop;

direct_loop(parloop,const,op2const)::=<<
$header()$
$parloop._global_reduction_args:{$reduction_kernel()$};separator="\n"$

$if(op2const.keys)$
/* op2 const declarations */
$op2const.values:{c | $opencl_const_declaration(cst=c)$};separator="\n"$
$endif$

$parloop._kernel._inst_code$
$kernel_stub()$
>>

opencl_const_declaration(cst)::=<<
__constant $cst._cl_type$ $cst._name$ $if(cst._is_scalar)$ = $cst._cl_value$$else$[] = {$cst._cl_value;separator=", "$}$endif$;
>>

kernel_stub()::=<<
__kernel
void $parloop._kernel._name$_stub (
  $parloop._unique_dats:{__global $it._cl_type$* $it._name$};separator=",\n"$$if(parloop._global_reduction_args)$,$endif$
  $parloop._global_reduction_args:{__global $it._dat._cl_type$* $it._dat._name$_reduction_array};separator=",\n"$$if(parloop._global_non_reduction_args)$,$endif$
  $parloop._global_non_reduction_args:{__global $it._dat._cl_type$* $it._dat._name$};separator=",\n"$
)
{
  unsigned int shared_memory_offset = $const.shared_memory_offset$;
  int set_size = $parloop._it_space.size$;

  __local char shared[$const.dynamic_shared_memory_size$];

  $parloop._direct_non_scalar_args:{__private $it._dat._cl_type$ $it._dat._name$_local[$it._dat._dim$];};separator="\n"$
  $parloop._direct_non_scalar_args:{__local $it._dat._cl_type$* $it._dat._name$_shared = (__local $it._dat._cl_type$*) (shared + shared_memory_offset * (get_local_id(0) / OP_WARPSIZE));};separator="\n"$

  $parloop._global_reduction_args:{__private $it._dat._cl_type$ $it._dat._name$_reduc_local[$it._dat._dim$];};separator="\n"$

  $parloop._global_reduction_args:{__local $it._dat._cl_type$ $it._dat._name$_reduc_tmp[$it._dat._dim$ * $const.threads_per_block$ * OP_WARPSIZE];};separator="\n"$

  int i_1;
  int i_2;

  int local_offset;
  int active_threads_count;
  int thread_id;

  // reduction zeroing
  $parloop._global_reduction_args:{for (i_1 = 0; i_1 < $it._dat._dim$; ++i_1) { $it._dat._name$_reduc_local[i_1] = $it._dat._cl_type_zero$; } };separator="\n"$

  thread_id = get_local_id(0) % OP_WARPSIZE;

  for (i_1 = get_global_id(0); i_1 < set_size; i_1 += get_global_size(0))
  {
    local_offset = i_1 - thread_id;
    active_threads_count = MIN(OP_WARPSIZE, set_size - local_offset);

    $parloop._direct_non_scalar_read_args:stagein();separator="\n"$
    $kernel_call()$
    $parloop._direct_non_scalar_written_args:stageout();separator="\n"$
  }
  $if(parloop._global_reduction_args)$
  // on device reduction
  $parloop._global_reduction_args:{for (i_1 = 0; i_1 < $it._dat._dim$; ++i_1) {
  $it._dat._name$_reduction_kernel(&$it._dat._name$_reduction_array[i_1 + get_group_id(0) * $it._dat._dim$], $it._dat._name$_reduc_local[i_1], $it._dat._name$_reduc_tmp);
}};separator="\n"$
  $endif$
}
>>

reduction_kernel()::=<<
__kernel
void $it._dat._name$_reduction_kernel (
  __global $it._dat._cl_type$* reduction_result,
  __private $it._dat._cl_type$ input_value,
  __local $it._dat._cl_type$* reduction_tmp_array
)
{
  int lid = get_local_id(0);
  if (lid < $const.partition_size$)
  {
    reduction_tmp_array[lid] = input_value;
  }
  barrier(CLK_LOCAL_MEM_FENCE);

  for(int offset = 1;
      offset < (int) get_local_size(0);
      offset <<= 1)
  {
    int mask = (offset << 1) - 1;
    if ( ((lid & mask) == 0) && ((lid + offset) < $const.partition_size$) ) {
      $reduction_op()$
    }
    barrier(CLK_LOCAL_MEM_FENCE);
  }
  if (lid == 0)
  {
    *reduction_result = reduction_tmp_array[0];
  }
}
>>

reduction_op()::=<<$if(it._is_INC)$
reduction_tmp_array[lid] += reduction_tmp_array[lid + offset];
$elseif(it._is_MIN)$
reduction_tmp_array[lid] += MIN(reduction_tmp_array[lid], reduction_tmp_array[lid + offset]);
$elseif(it._is_MAX)$
reduction_tmp_array[lid] += MAX(reduction_tmp_array[lid], reduction_tmp_array[lid + offset]);
$else$
SOMETHING WENT SOUTH;
$endif$>>

stagein(arg)::=<<
// $arg._dat._name$
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $it._dat._name$_shared[thread_id + i_2 * active_threads_count] = $arg._dat._name$[thread_id + i_2 * active_threads_count + local_offset * $arg._dat._dim$];
}
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $arg._dat._name$_local[i_2] = $it._dat._name$_shared[i_2 + thread_id * $arg._dat._dim$];
}
>>

stageout(arg)::=<<
// $arg._dat._name$
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $it._dat._name$_shared[i_2 + thread_id * $arg._dat._dim$] = $arg._dat._name$_local[i_2];
}
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $arg._dat._name$[thread_id + i_2 * active_threads_count + local_offset * $arg._dat._dim$] = $it._dat._name$_shared[thread_id + i_2 * active_threads_count];
}
>>

kernel_call()::=<<$parloop._kernel._name$($parloop._args:{$kernel_call_arg()$};separator=", "$);>>
kernel_call_arg()::=<<$if(it._d_is_staged)$$it._dat._name$_local$elseif(it._is_global_reduction)$$it._dat._name$_reduc_local$elseif(it._is_global)$$it._dat._name$$else$&$it._dat._name$[i_1]$endif$>>

header()::=<<
#if defined(cl_khr_fp64)
#pragma OPENCL EXTENSION cl_khr_fp64 : enable
#elif defined(cl_amd_fp64)
#pragma OPENCL EXTENSION cl_amd_fp64 : enable
#endif

#define OP_WARPSIZE $const.warpsize$
#define MIN(a,b) ((a < b) ? (a) : (b))
#define MAX(a,b) ((a < b) ? (b) : (a))
>>
