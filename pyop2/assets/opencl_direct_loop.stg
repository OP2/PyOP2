group opencl_direct_loop;

direct_loop(parloop,const,op2const)::=<<
$header()$
$parloop._global_reduction_args:{$reduction_kernel()$};separator="\n"$

$parloop._kernel._inst_code$
$kernel_stub()$
>>

kernel_stub()::=<<
__kernel
 __attribute__((reqd_work_group_size($const.threads_per_block$, 1, 1)))
void $parloop._kernel._name$_stub (
  $parloop._unique_dats:{__global $it._cl_type$* $it._name$,};separator="\n"$
  $parloop._global_reduction_args:{__global $it._dat._cl_type$* $it._dat._name$_reduction_array,};separator="\n"$
  $parloop._global_non_reduction_args:{__global $it._dat._cl_type$* $it._dat._name$,};separator="\n"$
  $op2const:{__constant $it._cl_type$* $it._name$,};separator="\n"$
  int set_size
)
{
  unsigned int shared_memory_offset = $const.shared_memory_offset$;

  __local char shared[$const.dynamic_shared_memory_size$] __attribute__((aligned(sizeof(long))));

  $parloop._direct_non_scalar_args:{__private $it._dat._cl_type$ $it._dat._name$_local[$it._dat._dim$];};separator="\n"$
  $parloop._direct_non_scalar_args:{__local $it._dat._cl_type$* $it._dat._name$_shared = (__local $it._dat._cl_type$*) (shared + shared_memory_offset * (get_local_id(0) / OP_WARPSIZE));};separator="\n"$

  $parloop._global_reduction_args:{__private $it._dat._cl_type$ $it._dat._name$_reduc_local[$it._dat._dim$];};separator="\n"$

  $parloop._global_reduction_args:{__local $it._dat._cl_type$* $it._dat._name$_reduc_tmp = (__local $it._dat._cl_type$*) shared;};separator="\n"$

  int i_1;
  int i_2;

  int local_offset;
  int active_threads_count;
  int thread_id;

  // reduction zeroing
  $parloop._global_reduction_args:{for (i_1 = 0; i_1 < $it._dat._dim$; ++i_1) { $it._dat._name$_reduc_local[i_1] = $it._dat._cl_type_zero$; } };separator="\n"$

  thread_id = get_local_id(0) % OP_WARPSIZE;

  for (i_1 = get_global_id(0); i_1 < set_size; i_1 += get_global_size(0))
  {
    local_offset = i_1 - thread_id;
    active_threads_count = MIN(OP_WARPSIZE, set_size - local_offset);

    $parloop._direct_non_scalar_read_args:stagein();separator="\n"$
    $kernel_call()$
    $parloop._direct_non_scalar_written_args:stageout();separator="\n"$
  }
  $if(parloop._global_reduction_args)$
  // on device reduction
  $parloop._global_reduction_args:{for (i_1 = 0; i_1 < $it._dat._dim$; ++i_1) {
  $it._dat._name$_reduction_kernel(&$it._dat._name$_reduction_array[i_1 + get_group_id(0) * $it._dat._dim$], $it._dat._name$_reduc_local[i_1], $it._dat._name$_reduc_tmp);
}};separator="\n"$
  $endif$
}
>>

reduction_kernel()::=<<
__kernel
void $it._dat._name$_reduction_kernel (
  __global $it._dat._cl_type$* reduction_result,
  __private $it._dat._cl_type$ input_value,
  __local $it._dat._cl_type$* reduction_tmp_array
)
{
  barrier(CLK_LOCAL_MEM_FENCE);
  int lid = get_local_id(0);
  reduction_tmp_array[lid] = input_value;
  barrier(CLK_LOCAL_MEM_FENCE);

  for(int offset = 1;
      offset < (int) get_local_size(0);
      offset <<= 1)
  {
    int mask = (offset << 1) - 1;
    if ( ((lid & mask) == 0) && ((lid + offset) < (int) get_local_size(0)) ) {
      $reduction_op()$
    }
    barrier(CLK_LOCAL_MEM_FENCE);
  }
  if (lid == 0)
  {
    *reduction_result = reduction_tmp_array[0];
  }
}
>>

reduction_op()::=<<$if(it._is_INC)$
reduction_tmp_array[lid] += reduction_tmp_array[lid + offset];
$elseif(it._is_MIN)$
reduction_tmp_array[lid] += MIN(reduction_tmp_array[lid], reduction_tmp_array[lid + offset]);
$elseif(it._is_MAX)$
reduction_tmp_array[lid] += MAX(reduction_tmp_array[lid], reduction_tmp_array[lid + offset]);
$else$
SOMETHING WENT SOUTH;
$endif$>>

stagein()::=<<
// $it._dat._name$
for (i_2 = 0; i_2 < $it._dat._dim$; ++i_2) {
  $it._dat._name$_shared[thread_id + i_2 * active_threads_count] = $it._dat._name$[thread_id + i_2 * active_threads_count + local_offset * $it._dat._dim$];
}
for (i_2 = 0; i_2 < $it._dat._dim$; ++i_2) {
  $it._dat._name$_local[i_2] = $it._dat._name$_shared[i_2 + thread_id * $it._dat._dim$];
}
>>

stageout()::=<<
// $it._dat._name$
for (i_2 = 0; i_2 < $it._dat._dim$; ++i_2) {
  $it._dat._name$_shared[i_2 + thread_id * $it._dat._dim$] = $it._dat._name$_local[i_2];
}
for (i_2 = 0; i_2 < $it._dat._dim$; ++i_2) {
  $it._dat._name$[thread_id + i_2 * active_threads_count + local_offset * $it._dat._dim$] = $it._dat._name$_shared[thread_id + i_2 * active_threads_count];
}
>>

kernel_call()::=<<$parloop._kernel._name$($parloop._args:{$kernel_call_arg()$};separator=", "$$kernel_call_const_args()$);>>
kernel_call_arg()::=<<$if(it._d_is_staged)$$it._dat._name$_local$elseif(it._is_global_reduction)$$it._dat._name$_reduc_local$elseif(it._is_global)$$it._dat._name$$else$&$it._dat._name$[i_1]$endif$>>

kernel_call_const_args()::=<<$if(op2const)$$op2const:{c |, $if(c._is_scalar)$*$c._name$$else$$c._name$$endif$}$$endif$>>

header()::=<<
/* Launch configuration:
 *   work group count     : $const.block_count$
 *   work group size      : $const.threads_per_block$
 *   local memory size    : $const.dynamic_shared_memory_size$
 *   shared memory offset : $const.shared_memory_offset$
 *   warpsize             : $const.warpsize$
 */
#if defined(cl_khr_fp64)
#if defined(cl_amd_fp64)
#pragma OPENCL EXTENSION cl_amd_fp64 : enable
#else
#pragma OPENCL EXTENSION cl_khr_fp64 : enable
#endif
#elif defined(cl_amd_fp64)
#pragma OPENCL EXTENSION cl_amd_fp64 : enable
#endif

#define OP_WARPSIZE $const.warpsize$
#define MIN(a,b) ((a < b) ? (a) : (b))
#define MAX(a,b) ((a < b) ? (b) : (a))
#define OP2_STRIDE(arr, idx) (arr[idx])
>>
