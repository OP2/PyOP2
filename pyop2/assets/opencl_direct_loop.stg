group opencl_direct_loop;

direct_loop(parloop,const)::=<<
$header()$
$parloop._d_reduction_args:{$reduction_kernel()$};separator="\n"$
$parloop._kernel._code$
$kernel_stub()$
>>

kernel_stub()::=<<
__kernel
void $parloop._kernel._name$_stub (
  $parloop._d_nonreduction_args:{__global $it._dat._cl_type$* $it._dat._name$};separator=",\n"$$if(parloop._d_reduction_args)$,$endif$
  $parloop._d_reduction_args:{__global $it._dat._cl_type$* $it._dat._name$_reduction_array};separator=",\n"$
)
{
  unsigned int shared_memory_offset = $const.shared_memory_offset$;
  int set_size = $parloop._it_space.size$;

  __local char shared[$const.dynamic_shared_memory_size$];

  $parloop._d_staged_args:{__private $it._dat._cl_type$ $it._dat._name$_local[$it._dat._dim$];};separator="\n"$
  $parloop._d_staged_args:{__local $it._dat._cl_type$* $it._dat._name$_shared = (__local $it._dat._cl_type$*) (shared + shared_memory_offset * (get_local_id(0) / OP_WARPSIZE));};separator="\n"$

  $parloop._d_reduction_args:{__private $it._dat._cl_type$ $it._dat._name$_reduc_local[$it._dat._dim$];};separator="\n"$

  $parloop._d_reduction_args:{__local $it._dat._cl_type$ $it._dat._name$_reduc_tmp[$it._dat._dim$ * $const.threads_per_block$ * OP_WARPSIZE];};separator="\n"$

  int i_1;
  int i_2;

  int local_offset;
  int active_threads_count;
  int thread_id;

  // reduction zeroing
  $parloop._d_reduction_args:{for (i_1 = 0; i_1 < $it._dat._dim$; ++i_1) { $it._dat._name$_reduc_local[i_1] = $it._dat._cl_type_zero$; } };separator="\n"$

  thread_id = get_local_id(0) % OP_WARPSIZE;

  for (i_1 = get_global_id(0); i_1 < set_size; i_1 += get_global_size(0))
  {
    local_offset = i_1 - thread_id;
    active_threads_count = MIN(OP_WARPSIZE, set_size - local_offset);

    $parloop._d_staged_in_args:stagein();separator="\n"$
    $kernel_call()$
    $parloop._d_staged_out_args:stageout();separator="\n"$
  }
  // on device reduction
  $parloop._d_reduction_args:{for (i_1 = 0; i_1 < $it._dat._dim$; ++i_1) {
  $it._dat._name$_reduction_kernel(&$it._dat._name$_reduction_array[i_1 + get_group_id(0) * $it._dat._dim$], $it._dat._name$_reduc_local[i_1], $it._dat._name$_reduc_tmp);
}};separator="\n"$
}
>>

reduction_kernel()::=<<
__kernel
void $it._dat._name$_reduction_kernel (
  __global $it._dat._cl_type$* reduction_result,
  __private $it._dat._cl_type$ input_value,
  __local $it._dat._cl_type$* reduction_tmp_array
)
{
  int lid = get_local_id(0);
  reduction_tmp_array[lid] = input_value;
  barrier(CLK_LOCAL_MEM_FENCE);

  for(int offset = 1;
      offset < get_local_size(0);
      offset <<= 1)
  {
    int mask = (offset << 1) - 1;
    if ((lid & mask) == 0) {
      $reduction_op()$
    }
    barrier(CLK_LOCAL_MEM_FENCE);
  }
  if (lid == 0)
  {
    *reduction_result = reduction_tmp_array[0];
  }
}
>>

reduction_op()::=<<$if(it._d_is_INC)$reduction_tmp_array[lid] += reduction_tmp_array[lid + offset];$endif$>>

stagein(arg)::=<<
// $arg._dat._name$
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $it._dat._name$_shared[thread_id + i_2 * active_threads_count] = $arg._dat._name$[thread_id + i_2 * active_threads_count + local_offset * 1];
}
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $arg._dat._name$_local[i_2] = $it._dat._name$_shared[i_2 + thread_id * 1];
}
>>

stageout(arg)::=<<
// $arg._dat._name$
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $it._dat._name$_shared[i_2 + thread_id * 1] = $arg._dat._name$_local[i_2];
}
for (i_2 = 0; i_2 < $arg._dat._dim$; ++i_2) {
  $arg._dat._name$[thread_id + i_2 * active_threads_count + local_offset * 1] = $it._dat._name$_shared[thread_id + i_2 * active_threads_count];
}
>>

kernel_call()::=<<$parloop._kernel._name$($parloop._args:{$kernel_call_arg()$};separator=", "$);>>
kernel_call_arg()::=<<$if(it._d_is_staged)$$it._dat._name$_local$elseif(it._d_is_INC)$$it._dat._name$_reduc_local$endif$>>

header()::=<<
#define OP_WARPSIZE $const.warpsize$
#define MIN(a,b) ((a < b) ? (a) : (b))
>>
