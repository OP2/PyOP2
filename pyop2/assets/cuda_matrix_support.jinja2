__device__ int pos(int row, int col, int* rowptr, int* colidx)
{
  for ( int k = rowptr[row]; k < rowptr[row+1]; k++ )
    if ( colidx[k] == col )
      return k;
  return INT_MAX;
}

__device__ inline void __atomic_add({{type}} *address, {{type}} val)
{
    {% if type == "float" %}
    atomicAdd(address, val);
    {% elif type == "double" %}
    unsigned long long int new_val, old;
    unsigned long long int old2 = __double_as_longlong(*address);
    do {
        old = old2;
        new_val = __double_as_longlong(__longlong_as_double(old) + val);
        old2 = atomicCAS((unsigned long long int *)address, old, new_val);
    } while (old2 != old)
        ;
    {% else %}
#error "Matrix entry type {{type}} not handled"
    {% endif %}
}

__global__ void __lma_to_csr({{type}} *lmadata,
                             {{type}} *csrdata,
                             int *rowptr,
                             int *colidx,
                             int *rowmap,
                             int rowmapdim,
                             int *colmap,
                             int colmapdim,
                             int nelems)
{
    int nentries_per_ele = rowmapdim * colmapdim;
    int n = threadIdx.x + blockIdx.x * blockDim.x;
    if ( n >= nelems * nentries_per_ele ) return;

    int e = n / nentries_per_ele;
    int i = (n - e * nentries_per_ele) / rowmapdim;
    int j = (n - e * nentries_per_ele - i * colmapdim);

    int offset = pos(rowmap[e * rowmapdim + i],
                     colmap[e * colmapdim + j],
                     rowptr, colidx);

    __atomic_add(csrdata + offset, lmadata[n]);
}

__global__ void __lma_to_csr_vector({{type}} *lmadata,
                                    {{type}} *csrdata,
                                    int *rowptr,
                                    int *colidx,
                                    int *rowmap,
                                    int rowmapdim,
                                    int rmult,
                                    int *colmap,
                                    int colmapdim,
                                    int cmult,
                                    int nelems)
{
    int nentries_per_ele = rowmapdim * colmapdim;
    int n = threadIdx.x + blockIdx.x * blockDim.x;
    if ( n >= nelems * nentries_per_ele ) return;

    int e = n / nentries_per_ele;
    int i = (n - e * nentries_per_ele) / rowmapdim;
    int j = (n - e * nentries_per_ele - i * colmapdim);

    int row = rmult * rowmap[e * rowmapdim + i];
    int col = cmult * colmap[e * colmapdim + j];
    for ( int k = 0; k < rmult; ++k ) {
        for ( int l = 0; l < cmult; ++l ) {
            int offset = pos(row + k, col + l,
                             rowptr, colidx);
            __atomic_add(csrdata + offset, lmadata[n*rmult*cmult + k*cmult + l]);
        }
    }
}
